{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "In this study, we are interested in evaluating the performance of a Neural Network using different parameters (the number of layers and the number of nodes per layer). In particular, the MNIST data set is used.\n",
    "\n",
    "Four models will be tested and confronted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vittoriopro/opt/anaconda3/envs/tensorflow_cpu_1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# ensure common functions across Python 2 and 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_v2_behavior() \n",
    "RANDOM_SEED=1234\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for the model\n",
    "\n",
    "The MNIST data set is loaded from the file train.csv and test.csv provided. The data is scaled using a StandardScaler. A validation set composed of 4.000 entries is created starting from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training DataFrame (first five rows):\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "\n",
      " test DataFrame (first five rows):\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "\n",
      "General description of the training MNIST DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n",
      "\n",
      "General description of the test MNIST DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n",
      "None\n",
      "\n",
      "General description of the training MNIST DataFrame:\n",
      "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
      "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
      "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
      "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
      "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
      "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
      "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
      "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
      "\n",
      "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
      "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
      "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
      "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
      "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
      "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
      "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
      "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
      "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
      "\n",
      "       pixel781  pixel782  pixel783  \n",
      "count   42000.0   42000.0   42000.0  \n",
      "mean        0.0       0.0       0.0  \n",
      "std         0.0       0.0       0.0  \n",
      "min         0.0       0.0       0.0  \n",
      "25%         0.0       0.0       0.0  \n",
      "50%         0.0       0.0       0.0  \n",
      "75%         0.0       0.0       0.0  \n",
      "max         0.0       0.0       0.0  \n",
      "\n",
      "[8 rows x 785 columns]\n",
      "\n",
      "General description of the test MNIST DataFrame:\n",
      "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
      "count  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0   \n",
      "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "        pixel8   pixel9  ...      pixel774      pixel775      pixel776  \\\n",
      "count  28000.0  28000.0  ...  28000.000000  28000.000000  28000.000000   \n",
      "mean       0.0      0.0  ...      0.164607      0.073214      0.028036   \n",
      "std        0.0      0.0  ...      5.473293      3.616811      1.813602   \n",
      "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "max        0.0      0.0  ...    253.000000    254.000000    193.000000   \n",
      "\n",
      "           pixel777      pixel778  pixel779  pixel780  pixel781  pixel782  \\\n",
      "count  28000.000000  28000.000000   28000.0   28000.0   28000.0   28000.0   \n",
      "mean       0.011250      0.006536       0.0       0.0       0.0       0.0   \n",
      "std        1.205211      0.807475       0.0       0.0       0.0       0.0   \n",
      "min        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "25%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "50%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "75%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "max      187.000000    119.000000       0.0       0.0       0.0       0.0   \n",
      "\n",
      "       pixel783  \n",
      "count   28000.0  \n",
      "mean        0.0  \n",
      "std         0.0  \n",
      "min         0.0  \n",
      "25%         0.0  \n",
      "50%         0.0  \n",
      "75%         0.0  \n",
      "max         0.0  \n",
      "\n",
      "[8 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# read data from MINST\n",
    "# creating data frame \n",
    "mnist_tr_df = pd.read_csv('train.csv')\n",
    "mnist_ts_df = pd.read_csv('test.csv')\n",
    "\n",
    "# check the pandas DataFrame object MNIST\n",
    "print('\\n training DataFrame (first five rows):')\n",
    "print(mnist_tr_df.head())\n",
    "print('\\n test DataFrame (first five rows):')\n",
    "print(mnist_ts_df.head())\n",
    "\n",
    "# basic info of the datframe\n",
    "print('\\nGeneral description of the training MNIST DataFrame:')\n",
    "print(mnist_tr_df.info())\n",
    "\n",
    "print('\\nGeneral description of the test MNIST DataFrame:')\n",
    "print(mnist_ts_df.info())\n",
    "\n",
    "# basic info of the datframe\n",
    "print('\\nGeneral description of the training MNIST DataFrame:')\n",
    "print(mnist_tr_df.describe())\n",
    "\n",
    "print('\\nGeneral description of the test MNIST DataFrame:')\n",
    "print(mnist_ts_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train object: <class 'numpy.ndarray'> (38000, 784)\n",
      "\n",
      "y_train object: <class 'pandas.core.series.Series'> (38000,)\n",
      "\n",
      "X_validation object: <class 'numpy.ndarray'> (4000, 784)\n",
      "\n",
      "y_validation object: <class 'pandas.core.series.Series'> (4000,)\n",
      "\n",
      "X_test object: <class 'numpy.ndarray'> (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "y_train_tot = mnist_tr_df.loc[:, 'label']\n",
    "x_train = mnist_tr_df.loc[:,'pixel0':'pixel783']\n",
    "\n",
    "x_test = mnist_ts_df.loc[:,'pixel0':'pixel783']\n",
    "\n",
    "X_train_scl = scaler.fit_transform(x_train).astype(np.float32)\n",
    "X_test = scaler.fit_transform(x_test).astype(np.float32)\n",
    "\n",
    "X_train = X_train_scl[:38000]\n",
    "X_val =  X_train_scl[-4000:]    \n",
    "\n",
    "y_train = y_train_tot[:38000]\n",
    "y_val =  y_train_tot[-4000:]   \n",
    "\n",
    "print('\\nX_train object:', type(X_train), X_train.shape)    \n",
    "print('\\ny_train object:', type(y_train),  y_train.shape)  \n",
    "print('\\nX_validation object:', type(X_val),  X_val.shape)  \n",
    "print('\\ny_validation object:', type(y_val),  y_val.shape)  \n",
    "print('\\nX_test object:', type(X_test),  X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "# Initialize metric names\n",
    "names = ['Number of Hidden Layers', 'Nodes per Layer', 'Time in Seconds',\n",
    "         'Training Set Accuracy', 'Validation Set Accuracy']\n",
    "\n",
    "# Set fixed parameters for models\n",
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Function that creates batch generator used in training\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "In this model, we will use 2 hidden layers composed of 100 nodes each. The accuracy of the training and validation set are displayed, along with the total execution time. The resulting prediction is stored in a CSV file to be uploaded in Kaggle for testing (score: 0.95928, UserId: Vittorio Pepe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1\n",
      "WARNING:tensorflow:From <ipython-input-6-5bf01eeade5c>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/vittoriopro/opt/anaconda3/envs/tensorflow_cpu_1/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "0 Train accuracy: 0.90544736 Val accuracy: 0.907\n",
      "1 Train accuracy: 0.9317632 Val accuracy: 0.9245\n",
      "2 Train accuracy: 0.94486845 Val accuracy: 0.9335\n",
      "3 Train accuracy: 0.95321053 Val accuracy: 0.93925\n",
      "4 Train accuracy: 0.9607895 Val accuracy: 0.94025\n",
      "5 Train accuracy: 0.96507895 Val accuracy: 0.9455\n",
      "6 Train accuracy: 0.96878946 Val accuracy: 0.94675\n",
      "7 Train accuracy: 0.97239476 Val accuracy: 0.94825\n",
      "8 Train accuracy: 0.974421 Val accuracy: 0.9525\n",
      "9 Train accuracy: 0.9773421 Val accuracy: 0.952\n",
      "10 Train accuracy: 0.9797895 Val accuracy: 0.95325\n",
      "11 Train accuracy: 0.98128945 Val accuracy: 0.954\n",
      "12 Train accuracy: 0.9829737 Val accuracy: 0.9545\n",
      "13 Train accuracy: 0.9847105 Val accuracy: 0.956\n",
      "14 Train accuracy: 0.98605263 Val accuracy: 0.958\n",
      "15 Train accuracy: 0.98739475 Val accuracy: 0.95625\n",
      "16 Train accuracy: 0.98839474 Val accuracy: 0.96\n",
      "17 Train accuracy: 0.9891053 Val accuracy: 0.9585\n",
      "18 Train accuracy: 0.99013156 Val accuracy: 0.96025\n",
      "19 Train accuracy: 0.9909737 Val accuracy: 0.958\n",
      "DURATION : 51.229236\n"
     ]
    }
   ],
   "source": [
    "# Model 1: 2 Hidden Layers with 100 Nodes per Layer\n",
    "\n",
    "print('\\nModel 1')\n",
    "\n",
    "# Start timer\n",
    "start = time.clock()\n",
    "\n",
    "n_hidden = 100\n",
    "\n",
    "# Reset the session\n",
    "#tf.disable_v2_behavior() \n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set X and y placeholders\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, 10, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    save_path = tf.train.Saver().save(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "#        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "\n",
    "# Record the clock time it takes\n",
    "duration = time.clock() - start\n",
    "print('DURATION :', duration)\n",
    "metrics['Model 1'] = [2, n_hidden, duration, acc_train, acc_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction are calculated for this model and saved in csv file for submission in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.train.Saver().restore(sess, \"./my_model_final.ckpt\")\n",
    "    Z = logits.eval(feed_dict={X: X_test})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "  \n",
    "df = pd.DataFrame(y_pred, columns=['Label'])\n",
    "df.index += 1 \n",
    "df.to_csv('Subm_mod_1.csv', index_label='ImageId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "\n",
    "In this model, we will use 2 hidden layers composed of 200 nodes each.  The accuracy of the training and validation set are displayed, along with the total execution time. The resulting prediction is stored in a CSV file to be uploaded in Kaggle for testing (score: 0.96157, UserId: Vittorio Pepe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2\n",
      "0 Train accuracy: 0.91492105 Val accuracy: 0.91075\n",
      "1 Train accuracy: 0.93747365 Val accuracy: 0.93\n",
      "2 Train accuracy: 0.9495 Val accuracy: 0.93475\n",
      "3 Train accuracy: 0.9578684 Val accuracy: 0.94025\n",
      "4 Train accuracy: 0.9641316 Val accuracy: 0.94475\n",
      "5 Train accuracy: 0.9695263 Val accuracy: 0.94625\n",
      "6 Train accuracy: 0.9725 Val accuracy: 0.95125\n",
      "7 Train accuracy: 0.9755526 Val accuracy: 0.9505\n",
      "8 Train accuracy: 0.9785789 Val accuracy: 0.953\n",
      "9 Train accuracy: 0.9811842 Val accuracy: 0.95325\n",
      "10 Train accuracy: 0.983 Val accuracy: 0.95625\n",
      "11 Train accuracy: 0.9848158 Val accuracy: 0.956\n",
      "12 Train accuracy: 0.98626316 Val accuracy: 0.95525\n",
      "13 Train accuracy: 0.9876842 Val accuracy: 0.95725\n",
      "14 Train accuracy: 0.9888684 Val accuracy: 0.95825\n",
      "15 Train accuracy: 0.99021053 Val accuracy: 0.95825\n",
      "16 Train accuracy: 0.9915263 Val accuracy: 0.95925\n",
      "17 Train accuracy: 0.99226314 Val accuracy: 0.959\n",
      "18 Train accuracy: 0.9930263 Val accuracy: 0.95975\n",
      "19 Train accuracy: 0.9937895 Val accuracy: 0.95925\n",
      "DURATION : 73.87842699999999\n"
     ]
    }
   ],
   "source": [
    "# Model 2: 2 Hidden Layers with 100 Nodes per Layer\n",
    "\n",
    "print('\\nModel 2')\n",
    "\n",
    "# Start timer\n",
    "start = time.clock()\n",
    "\n",
    "n_hidden = 200\n",
    "\n",
    "# Reset the session\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set X and y placeholders\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, 10, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    save_path = tf.train.Saver().save(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "#        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "\n",
    "# Record the clock time it takes\n",
    "duration = time.clock() - start\n",
    "print('DURATION :', duration)\n",
    "metrics['Model 2'] = [2, n_hidden, duration, acc_train, acc_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction are calculated for this model and saved in csv file for submission in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.train.Saver().restore(sess, \"./my_model_final.ckpt\")\n",
    "    Z = logits.eval(feed_dict={X: X_test})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    \n",
    "df = pd.DataFrame(y_pred, columns=['Label'])\n",
    "df.index += 1 \n",
    "df.to_csv('Subm_mod_2.csv', index_label='ImageId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "In this model, we will use 6 hidden layers composed of 100 nodes each. The accuracy of the training and validation set are displayed, along with the total execution time. The resulting prediction is stored in a CSV file to be uploaded in Kaggle for testing (score: 0.95600, UserId: Vittorio Pepe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 3\n",
      "0 Train accuracy: 0.8893421 Val accuracy: 0.88375\n",
      "1 Train accuracy: 0.9158684 Val accuracy: 0.91275\n",
      "2 Train accuracy: 0.9477105 Val accuracy: 0.934\n",
      "3 Train accuracy: 0.95721054 Val accuracy: 0.9405\n",
      "4 Train accuracy: 0.96771055 Val accuracy: 0.94525\n",
      "5 Train accuracy: 0.975 Val accuracy: 0.951\n",
      "6 Train accuracy: 0.9793158 Val accuracy: 0.95175\n",
      "7 Train accuracy: 0.9805526 Val accuracy: 0.94775\n",
      "8 Train accuracy: 0.9853947 Val accuracy: 0.95375\n",
      "9 Train accuracy: 0.98844737 Val accuracy: 0.95225\n",
      "10 Train accuracy: 0.9907105 Val accuracy: 0.95475\n",
      "11 Train accuracy: 0.9911579 Val accuracy: 0.9525\n",
      "12 Train accuracy: 0.99352634 Val accuracy: 0.95425\n",
      "13 Train accuracy: 0.9951579 Val accuracy: 0.95425\n",
      "14 Train accuracy: 0.9942368 Val accuracy: 0.954\n",
      "15 Train accuracy: 0.99739474 Val accuracy: 0.95625\n",
      "16 Train accuracy: 0.99789476 Val accuracy: 0.95475\n",
      "17 Train accuracy: 0.9980263 Val accuracy: 0.95425\n",
      "18 Train accuracy: 0.999 Val accuracy: 0.9535\n",
      "19 Train accuracy: 0.9990789 Val accuracy: 0.95425\n",
      "DURATION : 65.446789\n"
     ]
    }
   ],
   "source": [
    "# Model 3: 3 Hidden Layers with 300 Nodes per Layer\n",
    "print('\\nModel 3')\n",
    "\n",
    "# Start timer\n",
    "start = time.clock()\n",
    "\n",
    "n_hidden = 100\n",
    "\n",
    "# Reset the session\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set X and y placeholders\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, name=\"hidden3\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, name=\"hidden4\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, name=\"hidden5\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden6 = tf.layers.dense(hidden5, n_hidden, name=\"hidden6\",\n",
    "                              activation=tf.nn.relu)    \n",
    "    logits = tf.layers.dense(hidden6, 10, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    save_path = tf.train.Saver().save(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "#        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "\n",
    "# Record the clock time it takes\n",
    "duration = time.clock() - start\n",
    "print('DURATION :', duration)\n",
    "metrics['Model 3'] = [6, n_hidden, duration, acc_train, acc_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.train.Saver().restore(sess, \"./my_model_final.ckpt\")\n",
    "    Z = logits.eval(feed_dict={X: X_test})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "\n",
    "df = pd.DataFrame(y_pred, columns=['Label'])\n",
    "df.index += 1 \n",
    "df.to_csv('Subm_mod_3.csv', index_label='ImageId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4\n",
    "\n",
    "In this model, we will use 6 hidden layers composed of 200 nodes each. The accuracy of the training and validation set are displayed, along with the total execution time. The resulting prediction is stored in a CSV file to be uploaded in Kaggle for testing (score: 0.95971, UserId: Vittorio Pepe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 4\n",
      "0 Train accuracy: 0.9123684 Val accuracy: 0.90075\n",
      "1 Train accuracy: 0.94239473 Val accuracy: 0.92625\n",
      "2 Train accuracy: 0.95721054 Val accuracy: 0.9405\n",
      "3 Train accuracy: 0.9673947 Val accuracy: 0.94825\n",
      "4 Train accuracy: 0.97673684 Val accuracy: 0.953\n",
      "5 Train accuracy: 0.9817632 Val accuracy: 0.95425\n",
      "6 Train accuracy: 0.9847105 Val accuracy: 0.95675\n",
      "7 Train accuracy: 0.9855263 Val accuracy: 0.95625\n",
      "8 Train accuracy: 0.9919737 Val accuracy: 0.95825\n",
      "9 Train accuracy: 0.99339473 Val accuracy: 0.95775\n",
      "10 Train accuracy: 0.9950263 Val accuracy: 0.9585\n",
      "11 Train accuracy: 0.99671054 Val accuracy: 0.96075\n",
      "12 Train accuracy: 0.9973421 Val accuracy: 0.96175\n",
      "13 Train accuracy: 0.9985 Val accuracy: 0.96125\n",
      "14 Train accuracy: 0.9988684 Val accuracy: 0.96075\n",
      "15 Train accuracy: 0.99897367 Val accuracy: 0.9615\n",
      "16 Train accuracy: 0.9993684 Val accuracy: 0.96225\n",
      "17 Train accuracy: 0.9993684 Val accuracy: 0.961\n",
      "18 Train accuracy: 0.9996842 Val accuracy: 0.96225\n",
      "19 Train accuracy: 0.9994737 Val accuracy: 0.96125\n",
      "DURATION : 128.955616\n"
     ]
    }
   ],
   "source": [
    "# Model 4: 3 Hidden Layers with 200 Nodes per Layer\n",
    "print('\\nModel 4')\n",
    "\n",
    "# Start timer\n",
    "start = time.clock()\n",
    "\n",
    "n_hidden = 200\n",
    "\n",
    "# Reset the session\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set X and y placeholders\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, name=\"hidden3\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, name=\"hidden4\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, name=\"hidden5\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden6 = tf.layers.dense(hidden5, n_hidden, name=\"hidden6\",\n",
    "                              activation=tf.nn.relu)    \n",
    "    logits = tf.layers.dense(hidden6, 10, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    save_path = tf.train.Saver().save(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "#        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "\n",
    "# Record the clock time it takes\n",
    "duration = time.clock() - start\n",
    "print('DURATION :', duration)\n",
    "metrics['Model 4'] = [6, n_hidden, duration, acc_train, acc_val]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.train.Saver().restore(sess, \"./my_model_final.ckpt\")\n",
    "    Z = logits.eval(feed_dict={X: X_test})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    \n",
    "df = pd.DataFrame(y_pred, columns=['Label'])\n",
    "df.index += 1 \n",
    "df.to_csv('Subm_mod_4.csv', index_label='ImageId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark results\n",
    "\n",
    "In the below table, a summary of the models, their characteristics, and performances are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Hidden Layers</th>\n",
       "      <th>Nodes per Layer</th>\n",
       "      <th>Time in Seconds</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>51.229236</td>\n",
       "      <td>0.990974</td>\n",
       "      <td>0.95800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>73.878427</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.95925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>65.446789</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.95425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>128.955616</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.96125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Number of Hidden Layers  Nodes per Layer  Time in Seconds  \\\n",
       "Model 1                        2              100        51.229236   \n",
       "Model 2                        2              200        73.878427   \n",
       "Model 3                        6              100        65.446789   \n",
       "Model 4                        6              200       128.955616   \n",
       "\n",
       "         Training Set Accuracy  Validation Set Accuracy  \n",
       "Model 1               0.990974                  0.95800  \n",
       "Model 2               0.993789                  0.95925  \n",
       "Model 3               0.999079                  0.95425  \n",
       "Model 4               0.999474                  0.96125  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics dictionary to dataframe for display\n",
    "results_summary = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "results_summary.columns = names\n",
    "\n",
    "# Sort by model number\n",
    "results_summary.reset_index(inplace=True)\n",
    "results_summary.sort_values(by=['index'], axis=0, inplace=True)\n",
    "results_summary.set_index(['index'], inplace=True)\n",
    "results_summary.index.name = None\n",
    "\n",
    "# Export to csv\n",
    "results_summary.to_csv('results_summary.csv')\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Model 1 score: 0.95928\n",
    "Model 2 score: 0.96157\n",
    "Model 3 score: 0.95600\n",
    "Model 4 score: 0.95971\n",
    "\n",
    "The best model on the test set is Model 2. This model has 2 hidden layers and 200 nodes per layer. \n",
    "\n",
    "Confronting with the other models, increasing the numebr of layers per node increase the ccuracy of the model. On the other hand increasing the number of hidden layers increase training time and generate more overfitting. In general, and specially for the case of the network with more layers, the models  should be modified adding some regularization technique and dropout to decrease the overfitting problem.\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
